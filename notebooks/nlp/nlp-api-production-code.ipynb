{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2504f1b4",
   "metadata": {},
   "source": [
    "# NLP for Production (industry/real-world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dcecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cory/Desktop/Lectures/notebooks/nlp'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4993a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cory/Desktop/Lectures'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056caed",
   "metadata": {},
   "source": [
    "# 1. Leveraging object orientied code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145a06e",
   "metadata": {},
   "source": [
    "## 1.A Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a989d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleOperationPerformer:\n",
    "    def perform_string_print(self, input_string):\n",
    "        print(\"Running perform_string_print...\")\n",
    "        result = input_string\n",
    "        print(f\"The result of string_print function: {result}\")\n",
    "        return result\n",
    "\n",
    "    def perform_addition(self, num1, num2, num3):\n",
    "        print(\"Running perform_addition...\")\n",
    "        final = num1 + num2 + num3\n",
    "        print(f\"The result of add_func function: {final}\")\n",
    "        return final\n",
    "\n",
    "    def run_all_operations(self):\n",
    "        print(\"\\nStarting run_all_operations...\")\n",
    "        self.perform_string_print('LOOK MOM I CAN PRINT')\n",
    "        self.perform_addition(5, 3, 2)\n",
    "        print(\"Finished run_all_operations.\")\n",
    "\n",
    "# Let's create our SimpleOperationPerformer tool\n",
    "ot = SimpleOperationPerformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94a251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running operations individually:\n",
      "Running perform_string_print...\n",
      "The result of string_print function: Hello from individual call!\n",
      "Running perform_addition...\n",
      "The result of add_func function: 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's tell it to run each action individually\n",
    "print(\"\\nRunning operations individually:\")\n",
    "ot.perform_string_print('Hello from individual call!')\n",
    "ot.perform_addition(10, 20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b309d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting run_all_operations...\n",
      "Running perform_string_print...\n",
      "The result of string_print function: LOOK MOM I CAN PRINT\n",
      "Running perform_addition...\n",
      "The result of add_func function: 10\n",
      "Finished run_all_operations.\n"
     ]
    }
   ],
   "source": [
    "# And let's also run all operations together\n",
    "ot.run_all_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420671f",
   "metadata": {},
   "source": [
    "## 1.1 Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04395f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "class DataProcessor:\n",
    "    # '__init__' is a special function that runs automatically when you make a DataProcessor tool.\n",
    "    def __init__(self, intermediate_folder=\"intermediate/\", raw_folder=\"raw/\"):\n",
    "        # Inside '__init__', we're giving our new startup tool some initial settings.\n",
    "        # We're setting up where this tool will look for and store its information.\n",
    "        self.intermediate_folder = intermediate_folder  # This tells the tool where to put partially finished info.\n",
    "        self.raw_folder = raw_folder                    # This tells the tool where the original info is kept.\n",
    "        self.df_macro = None                             # This will hold macro info after we download it.\n",
    "        self.df_oecd = None                              # This will hold OECD info after we download it.\n",
    "\n",
    "    # This is a new ability for our tool: downloading macro info from a website.\n",
    "    def download_macro(self, macro_url):\n",
    "        self.df_macro = pd.read_stata(macro_url) # We use a special tool (pd.read_stata) to read the info directly from the web address.\n",
    "        # Once downloaded, we store the info within our tool and then give it back.\n",
    "        return self.df_macro\n",
    "\n",
    "    # Here's another new ability: downloading info from the OECD website.\n",
    "    def download_oecd(self, oecd_url):\n",
    "        \n",
    "        response = requests.get(oecd_url) # We ask the website for the info.\n",
    "        response.raise_for_status() # If something went wrong while asking, this will let us know.\n",
    "        data = io.StringIO(response.text) # We take the text info we got and treat it like a file.\n",
    "        self.df_oecd = pd.read_csv(data) # Then, we use another special tool (pd.read_csv) to understand this info.\n",
    "\n",
    "        return self.df_oecd # We store this info in our tool and then give it back.\n",
    "\n",
    "# Let's say you want to create a DataProcessor startup tool to organize your files and download data.\n",
    "# When you do this: The '__init__' function automatically runs, setting up the initial storage locations\n",
    "dp = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e9abd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO3</th>\n",
       "      <th>year</th>\n",
       "      <th>ADB_infl</th>\n",
       "      <th>AHSTAT_infl</th>\n",
       "      <th>AMF_infl</th>\n",
       "      <th>BCEAO_infl</th>\n",
       "      <th>BIS_infl</th>\n",
       "      <th>BORDO_infl</th>\n",
       "      <th>CEPAC_infl</th>\n",
       "      <th>EUS_infl</th>\n",
       "      <th>...</th>\n",
       "      <th>OECD_KEI_infl</th>\n",
       "      <th>WB_CC_infl</th>\n",
       "      <th>WDI_infl</th>\n",
       "      <th>WDI_ARC_infl</th>\n",
       "      <th>CS1_infl</th>\n",
       "      <th>CS2_infl</th>\n",
       "      <th>infl</th>\n",
       "      <th>chainlinking_ratio</th>\n",
       "      <th>source</th>\n",
       "      <th>source_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.131044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMF_WEO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.108963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMF_WEO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ISO3    year  ADB_infl  AHSTAT_infl  AMF_infl  BCEAO_infl  BIS_infl  \\\n",
       "0  ZWE  2029.0       NaN          NaN       NaN         NaN       NaN   \n",
       "1  ZWE  2028.0       NaN          NaN       NaN         NaN       NaN   \n",
       "\n",
       "   BORDO_infl  CEPAC_infl  EUS_infl  ...  OECD_KEI_infl  WB_CC_infl  WDI_infl  \\\n",
       "0         NaN         NaN       NaN  ...            NaN         NaN       NaN   \n",
       "1         NaN         NaN       NaN  ...            NaN         NaN       NaN   \n",
       "\n",
       "   WDI_ARC_infl  CS1_infl  CS2_infl      infl  chainlinking_ratio   source  \\\n",
       "0           NaN       NaN       NaN  5.131044                 1.0  IMF_WEO   \n",
       "1           NaN       NaN       NaN  5.108963                 1.0  IMF_WEO   \n",
       "\n",
       "   source_change  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_df = dp.download_macro(\n",
    "    macro_url = 'https://github.com/KMueller-Lab/Global-Macro-Database/raw/refs/heads/main/data/final/chainlinked_infl.dta'\n",
    ")\n",
    "dp.df_macro.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d957427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>REF_AREA</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>MEASURE</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>UNIT_MEASURE</th>\n",
       "      <th>PRICE_BASE</th>\n",
       "      <th>TRANSFORMATION</th>\n",
       "      <th>ADJUSTMENT</th>\n",
       "      <th>CONVERSION_TYPE</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>OBS_STATUS</th>\n",
       "      <th>UNIT_MULT</th>\n",
       "      <th>BASE_PER</th>\n",
       "      <th>DECIMALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OECD.SDD.TPS:DSD_PDB@DF_PDB_ULC_Q(1.0)</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Q</td>\n",
       "      <td>ULCE</td>\n",
       "      <td>_T</td>\n",
       "      <td>PP</td>\n",
       "      <td>V</td>\n",
       "      <td>G1</td>\n",
       "      <td>S</td>\n",
       "      <td>NC</td>\n",
       "      <td>1990-Q4</td>\n",
       "      <td>-1.254723</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OECD.SDD.TPS:DSD_PDB@DF_PDB_ULC_Q(1.0)</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Q</td>\n",
       "      <td>ULCE</td>\n",
       "      <td>_T</td>\n",
       "      <td>PP</td>\n",
       "      <td>V</td>\n",
       "      <td>G1</td>\n",
       "      <td>S</td>\n",
       "      <td>NC</td>\n",
       "      <td>1991-Q1</td>\n",
       "      <td>1.116150</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DATAFLOW REF_AREA FREQ MEASURE ACTIVITY  \\\n",
       "0  OECD.SDD.TPS:DSD_PDB@DF_PDB_ULC_Q(1.0)      AUS    Q    ULCE       _T   \n",
       "1  OECD.SDD.TPS:DSD_PDB@DF_PDB_ULC_Q(1.0)      AUS    Q    ULCE       _T   \n",
       "\n",
       "  UNIT_MEASURE PRICE_BASE TRANSFORMATION ADJUSTMENT CONVERSION_TYPE  \\\n",
       "0           PP          V             G1          S              NC   \n",
       "1           PP          V             G1          S              NC   \n",
       "\n",
       "  TIME_PERIOD  OBS_VALUE OBS_STATUS  UNIT_MULT  BASE_PER  DECIMALS  \n",
       "0     1990-Q4  -1.254723          A          0       NaN         2  \n",
       "1     1991-Q1   1.116150          A          0       NaN         2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd_df = dp.download_oecd(\n",
    "    oecd_url = \"https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_PDB@DF_PDB_ULC_Q,1.0/.Q.......?startPeriod=1990-Q4&format=csv\"\n",
    ")\n",
    "dp.df_oecd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c441a",
   "metadata": {},
   "source": [
    "## 1.2 Data pipeline advanced\n",
    "\n",
    " - from src.examples.data_processor python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "890455e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.examples.data_processor import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61dd902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running download_macro...\n",
      "Macro data downloaded successfully.\n",
      "Running download_oecd...\n",
      "OECD data downloaded successfully.\n",
      "Running filter_rename_macro_nz...\n",
      "Macro data filtered and renamed for NZ.\n",
      "Running filter_rename_oecd_nz...\n",
      "OECD data filtered and renamed for NZ.\n",
      "Running convert_datetime_macro_nz...\n",
      "Macro dates converted to datetime.\n",
      "Running convert_datetime_oecd_nz...\n",
      "OECD dates converted to datetime.\n",
      "Running set_index_macro_nz...\n",
      "Macro data index set to country and date.\n",
      "Running set_index_oecd_nz...\n",
      "OECD data index set to country and date.\n",
      "Running merge_data...\n",
      "Macro and OECD data merged.\n",
      "Running export_data...\n",
      "Merged data exported to: data/intermediate/processed/merged_data_nz.csv\n",
      "Raw OECD data exported to: data/raw/oecd_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's create our DataProcessor tool.\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Now, let's define the web addresses for our data:\n",
    "macro_data_url = 'https://github.com/KMueller-Lab/Global-Macro-Database/raw/refs/heads/main/data/final/chainlinked_infl.dta'\n",
    "oecd_data_url = \"https://sdmx.oecd.org/public/rest/data/OECD.SDD.TPS,DSD_PDB@DF_PDB_ULC_Q,1.0/.Q.......?startPeriod=1990-Q4&format=csv\"\n",
    "\n",
    "# Now, we will run each method of our 'processor' tool one by one.\n",
    "\n",
    "# 1. Download macro data\n",
    "macro_df = processor.download_macro(macro_data_url)\n",
    "\n",
    "# 2. Download OECD data\n",
    "oecd_df = processor.download_oecd(oecd_data_url)\n",
    "\n",
    "# 3. Filter and rename macro data for New Zealand\n",
    "macro_nz_df = processor.filter_rename_macro_nz()\n",
    "\n",
    "# 4. Filter and rename OECD data for New Zealand\n",
    "oecd_nz_df = processor.filter_rename_oecd_nz()\n",
    "\n",
    "# 5. Convert datetime in macro data\n",
    "macro_nz_df_dt = processor.convert_datetime_macro_nz()\n",
    "\n",
    "# 6. Convert datetime in OECD data\n",
    "oecd_nz_df_dt = processor.convert_datetime_oecd_nz()\n",
    "\n",
    "# 7. Set index for macro data\n",
    "macro_nz_df_indexed = processor.set_index_macro_nz()\n",
    "\n",
    "# 8. Set index for OECD data\n",
    "oecd_nz_df_indexed = processor.set_index_oecd_nz()\n",
    "\n",
    "# 9. Merge the two datasets\n",
    "merged_df = processor.merge_data()\n",
    "\n",
    "# 10. Export the processed and raw data\n",
    "processor.export_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a5cc8",
   "metadata": {},
   "source": [
    "# 2. Applying OOP code to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d0077c",
   "metadata": {},
   "source": [
    "## 2.1 Running local LLMs (from your computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e64f3",
   "metadata": {},
   "source": [
    "### 2.1.1 Ollama\n",
    "- https://ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d829f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm.inference.llm_inference_ollama import LLMInferenceOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4444390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLMInferenceOllama(model_name= \"gemma3:270m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0346d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llava:7b\n",
      "mistral:7b\n",
      "gemma3:270m\n",
      "qwen3:0.6b\n",
      "deepseek-r1:70b\n",
      "gemma3:27b\n",
      "llama3.1:8b\n",
      "qwen3:32b\n",
      "qwen2.5-coder:32b\n",
      "magistral:latest\n",
      "llama3.2:latest\n",
      "deepseek-r1:32b\n",
      "gpt-oss:20b\n"
     ]
    }
   ],
   "source": [
    "models = llm.list_models()\n",
    "for model in models['models']:\n",
    "    print(f\"{model['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547e45f",
   "metadata": {},
   "source": [
    "### 2.1.2 LMstudio \n",
    "- https://lmstudio.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cea4eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model: liquid/lfm2-1.2b\n",
      "Loaded models: ['liquid/lfm2-1.2b']\n",
      "Model loaded in memory: True\n",
      "Prompt Length: 30\n",
      "資本規制について以下に経済学的な観点から回答します。\n",
      "\n",
      "- **定義**: 資本規制とは、金融市場における資金の流れを管理・制限する政府の政策や法律を指します。これは、金融安定の維持、金融危機の防止、経済成長の促進を目的としています。\n",
      "\n",
      "- **目的**:\n",
      "  - **金融安定の維持**: 資本の急激な流入や流出による市場の不安定化を防ぎ、金融システムの健全性を保つ。\n",
      "  - **経済成長の促進**: 適切な資本の流れを確保することで、投資機会の拡大や経済活動の活性化を図る。\n",
      "  - **不正行為の防止**: マネーロンダリングやテロ資金供与などの違法行為を抑止する。\n",
      "  - **為替レートの安定**: 過度な資本移動による為替レートの急激な変動を防ぐ。\n",
      "\n",
      "- **種類**:\n",
      "  - **流出規制**: 資本が国外に急速に流出するのを防ぐための規制（例：外貨持ち出し制限）。\n",
      "  - **流入規制**: 外国からの資本流入を管理するための規制（例：投資上限の設定）。\n",
      "  -\n"
     ]
    }
   ],
   "source": [
    "from src.llm.inference.llm_inference_lmstudio import LLMInferenceLMStudio\n",
    "llm = LLMInferenceLMStudio(model_name=\"liquid/lfm2-1.2b\")\n",
    "llm.check_model_loaded()\n",
    "prompt = \"資本規制について教えてください。箇条書きで回答してください。\"\n",
    "system_message = \"あなたは経済学者です。\"\n",
    "llm.load_prompt(prompt, system_message=system_message, verbose=True)\n",
    "result = llm.infer(max_tokens_response=300)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00ca0c",
   "metadata": {},
   "source": [
    "## 2.2 Running LLMs via Groq API (similar to Gemini, Claude, etc)\n",
    "\n",
    "- Note groq is not the api affiliated with X's Grok LLM\n",
    "    - https://groq.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b88b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 30\n"
     ]
    }
   ],
   "source": [
    "from src.llm.inference.llm_inference_groqinference import LLMInferenceGroqInference\n",
    "llm = LLMInferenceGroqInference(model_name=\"llama-3.3-70b-versatile\")\n",
    "prompt = \"資本規制について教えてください。箇条書きで回答してください。\"\n",
    "system_message = \"あなたは経済学者です。\"\n",
    "llm.load_prompt(prompt, system_message=system_message, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39157a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資本規制については以下の点が重要です。\n",
      "\n",
      "*   資本規制は、銀行や金融機関が保有する資本の水準を規定することで、金融の安定性とリスクを管理することを目的としています。\n",
      "*   バーゼル協定が資本規制の国際基準として広く採用されており、銀行が最低限の資本規制を満たす必要があります。\n",
      "*   資本規制により、銀行はリスクを抑制し、経済の変動に耐える能力を高めることができます。\n",
      "*   また、資本規制は金融の安定性を維持し、金融危機の発生を防ぐ役割も果たしています。\n",
      "*   ただし、資本規制には、金融機関がより厳格な規制に従わなければならないため、融資の柔軟性が制限される可能性があります。\n",
      "*   さらに、規制の厳格性によって、金融機関がより慎重な貸し出しを行うようになり、経済の成長が制限される可能性もあります。\n",
      "*   資本規制は、金融機関と経済の成長をバランスさせる必要があるため、調整が必要です。\n"
     ]
    }
   ],
   "source": [
    "result = llm.infer(max_tokens_response=300)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179eb44",
   "metadata": {},
   "source": [
    "## 2.3 Use previous two OOP coding frameworks in more agnostic pipeline runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1420c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm.llm_inference_runner import LLMInferenceRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e1f9a",
   "metadata": {},
   "source": [
    "### 2.3.1 Run from lm studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a57d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 45\n",
      "\n",
      "Running batch inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved: 2/3 items processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n",
      "\n",
      "Input 1: The quick brown fox jumps over the lazy dog. This ...\n",
      "Output 1: Topic: Typography and Pangrams\n",
      "\n",
      "Input 2: Machine learning is a subset of artificial intelli...\n",
      "Output 2: Topic: Artificial Intelligence and Machine Learning.\n",
      "\n",
      "Input 3: Climate change is affecting weather patterns aroun...\n",
      "Output 3: Topic: Climate Change and Extreme Weather Events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "runner = LLMInferenceRunner(\n",
    "    llm_provider='lmstudio',\n",
    "    model_name='liquid/lfm2-1.2b',\n",
    "    save_path='./test_results'\n",
    ")\n",
    "\n",
    "prompt = \"Classify this text according to topic: {text}\"\n",
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "runner.set_prompt(prompt, system_message=system_message, verbose=True)\n",
    "\n",
    "test_inputs = [\n",
    "    \"The quick brown fox jumps over the lazy dog. This is a common pangram used in typography.\",\n",
    "    \"Machine learning is a subset of artificial intelligence that enables computers to learn from data.\",\n",
    "    \"Climate change is affecting weather patterns around the world, causing more extreme weather events.\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning batch inference...\")\n",
    "results = runner.infer(test_inputs, seconds_delay=1, save_intermediate_n=2)\n",
    "\n",
    "print(\"\\n=== Results ===\")\n",
    "for i, (inp, out) in enumerate(zip(test_inputs, results)):\n",
    "    print(f\"\\nInput {i+1}: {inp[:50]}...\")\n",
    "    print(f\"Output {i+1}: {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9bb6b",
   "metadata": {},
   "source": [
    "### 2.3.2 Run from groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "178d0f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmstudio\n",
      "liquid/lfm2-1.2b\n"
     ]
    }
   ],
   "source": [
    "print(runner.llm_provider)\n",
    "print(runner.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d678284",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.llm_provider = 'groqinference'\n",
    "runner.model_name = 'llama-3.3-70b-versatile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bed7a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groqinference\n",
      "llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "print(runner.llm_provider)\n",
    "print(runner.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55f05dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 45\n"
     ]
    }
   ],
   "source": [
    "runner.set_prompt(prompt, system_message=system_message, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f31850f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved: 2/3 items processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n",
      "\n",
      "Input 1: The quick brown fox jumps over the lazy dog. This ...\n",
      "Output 1: This text is classified under the topic of \"Typography\" and \"Language.\" More specifically, it's a pangram example.\n",
      "\n",
      "Input 2: Machine learning is a subset of artificial intelli...\n",
      "Output 2: Topic: Artificial Intelligence and Machine Learning\n",
      "\n",
      "Input 3: Climate change is affecting weather patterns aroun...\n",
      "Output 3: The text is classified under the topic of \"Climate Change and Extreme Weather Events.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = runner.infer(test_inputs, seconds_delay=1, save_intermediate_n=2)\n",
    "print(\"\\n=== Results ===\")\n",
    "for i, (inp, out) in enumerate(zip(test_inputs, results)):\n",
    "    print(f\"\\nInput {i+1}: {inp[:50]}...\")\n",
    "    print(f\"Output {i+1}: {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6424e50",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fc572",
   "metadata": {},
   "source": [
    "# 3. MLOps/LLMOps Tech Stack\n",
    "\n",
    "# 3.A Configuration Management Best Practices\n",
    "\n",
    "- **OOP coding practices for configs**: Use inheritance patterns (base configs with environment/model-specific overrides) to manage shared parameters across pipeline stages (3.1), model variants (3.2), experiment sets (3.3), and LLM prompt templates (3.4)\n",
    "- **YAML for pipeline and input tracking**: Define reproducible pipelines in DVC (3.1) with input data versions, log experiment parameters in W&B (3.3), configure model metadata in MLflow (3.2), and version LLM prompts in Langfuse (3.4) using YAML\n",
    "- **Git version control for configurations**: Track all YAML configs, pipeline definitions, and code changes in Git to maintain audit trails, enable rollbacks, and coordinate changes across pipeline components (3.1), model versions (3.2), experiments (3.3), and LLM workflows (3.4)\n",
    "- **Secrets and credentials separation**: Externalize API keys, database credentials, and cloud storage tokens from config files using environment variables or secret managers to safely version control configurations across all tools (3.1-3.4)\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 Pipeline Management (DVC)\n",
    "- **Pipeline orchestration**: Define end-to-end ML pipelines with dependencies between data preprocessing, training, and evaluation stages\n",
    "- **Reproducibility**: Lock data versions, code commits, and dependencies together to recreate exact training runs\n",
    "- **Remote storage integration**: Track large datasets and models in S3/GCS/Azure without bloating Git repos\n",
    "\n",
    "## 3.2 Model Registry & Versioning (MLflow/DVC)\n",
    "- **Centralized model storage**: Register, version, and track model artifacts with metadata in a single source of truth\n",
    "- **Stage transitions**: Promote models through staging/production with approval workflows and rollback capabilities\n",
    "- **A/B testing support**: Deploy multiple model versions simultaneously for comparison and gradual rollout\n",
    "\n",
    "## 3.3 Experiment Management (Weights & Biases)\n",
    "- **Hyperparameter tracking**: Log all training configs, metrics, and results automatically for easy comparison across experiments\n",
    "- **Real-time monitoring**: Visualize training metrics (loss, accuracy) live during runs to catch issues early\n",
    "- **Artifact management**: Store model checkpoints, datasets, and predictions with full lineage tracking\n",
    "\n",
    "## 3.4 LLMOps (Langfuse/LangChain)\n",
    "- **Production observability**: Track LLM calls, token usage, latency, and costs with prompt versioning and performance analytics\n",
    "- **Complex workflows**: Build multi-step LLM applications with chains, agents, and memory for reasoning tasks\n",
    "- **Tool integration**: Connect LLMs to external APIs, databases, and vector stores for retrieval-augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fff019",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
